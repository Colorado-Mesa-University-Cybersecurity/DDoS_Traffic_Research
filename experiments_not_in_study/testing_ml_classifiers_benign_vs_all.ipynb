{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import os, platform, pprint, sys\r\n",
    "import fastai\r\n",
    "import keras\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sn\r\n",
    "import sklearn\r\n",
    "\r\n",
    "# from fastai.tabular.data import TabularDataLoaders\r\n",
    "# from fastai.tabular.all import FillMissing, Categorify, Normalize, tabular_learner, accuracy, ClassificationInterpretation, ShowGraphCallback\r\n",
    "\r\n",
    "from itertools import cycle\r\n",
    "\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.metrics import CategoricalAccuracy, Recall, Precision, AUC\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.utils import to_categorical, normalize\r\n",
    "\r\n",
    "from math import sqrt\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.metrics import roc_curve, auc\r\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "\r\n",
    "seed: int = 14\r\n",
    "\r\n",
    "\r\n",
    "# set up pretty printer for easier data evaluation\r\n",
    "pretty = pprint.PrettyPrinter(indent=4, width=30).pprint\r\n",
    "\r\n",
    "\r\n",
    "# declare file paths for the data we will be working on\r\n",
    "file_path_1: str = '../data/prepared/baseline/Benign_vs_DDoS.csv'\r\n",
    "file_path_2: str = '../data/prepared/timebased/Benign_vs_DDoS.csv'\r\n",
    "modelPath  : str = './models'\r\n",
    "\r\n",
    "\r\n",
    "# print library and python versions for reproducibility\r\n",
    "print(\r\n",
    "    f'''\r\n",
    "    python:\\t{platform.python_version()}\r\n",
    "\r\n",
    "    \\tfastai:\\t\\t{fastai.__version__}\r\n",
    "    \\tkeras:\\t\\t{keras.__version__}\r\n",
    "    \\tmatplotlib:\\t{mpl.__version__}\r\n",
    "    \\tnumpy:\\t\\t{np.__version__}\r\n",
    "    \\tpandas:\\t\\t{pd.__version__}\r\n",
    "    \\tseaborn:\\t{sn.__version__}\r\n",
    "    \\tsklearn:\\t{sklearn.__version__}\r\n",
    "    '''\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "    python:\t3.7.10\n",
      "\n",
      "    \tfastai:\t\t2.4.1\n",
      "    \tkeras:\t\t2.3.1\n",
      "    \tmatplotlib:\t3.3.4\n",
      "    \tnumpy:\t\t1.20.3\n",
      "    \tpandas:\t\t1.2.5\n",
      "    \tseaborn:\t0.11.1\n",
      "    \tsklearn:\t0.24.2\n",
      "    \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def load_data(filePath: str) -> pd.DataFrame:\r\n",
    "    '''\r\n",
    "        Loads the Dataset from the given filepath and caches it for quick access in the future\r\n",
    "        Function will only work when filepath is a .csv file\r\n",
    "    '''\r\n",
    "\r\n",
    "    # slice off the ./CSV/ from the filePath\r\n",
    "    if filePath[0] == '.' and filePath[1] == '.':\r\n",
    "        filePathClean: str = filePath[17::]\r\n",
    "        pickleDump: str = f'../data/cache/{filePathClean}.pickle'\r\n",
    "    else:\r\n",
    "        pickleDump: str = f'../data/cache/{filePath}.pickle'\r\n",
    "    \r\n",
    "    print(f'Loading Dataset: {filePath}')\r\n",
    "    print(f'\\tTo Dataset Cache: {pickleDump}\\n')\r\n",
    "    \r\n",
    "    # check if data already exists within cache\r\n",
    "    if os.path.exists(pickleDump):\r\n",
    "        df = pd.read_pickle(pickleDump)\r\n",
    "        \r\n",
    "    # if not, load data and cache it\r\n",
    "    else:\r\n",
    "        df = pd.read_csv(filePath, low_memory=True)\r\n",
    "        df.to_pickle(pickleDump)\r\n",
    "\r\n",
    "    \r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def show_conf_matrix(model=None, X_test=None, y_test=None, classes=[], file=''):\r\n",
    "    # Techniques from https://stackoverflow.com/questions/29647749/seaborn-showing-scientific-notation-in-heatmap-for-3-digit-numbers\r\n",
    "    # and https://stackoverflow.com/questions/35572000/how-can-i-plot-a-confusion-matrix#51163585\r\n",
    "    \r\n",
    "    predictions = model.predict(X_test)\r\n",
    "    matrix = [ [ 0 for j in range(len(predictions[0])) ]  for i in range(len(predictions[0])) ]\r\n",
    "    for i in range(len(predictions)):\r\n",
    "        pred = predictions[i]\r\n",
    "        test = y_test[i]\r\n",
    "\r\n",
    "        guess = np.argmax(pred)\r\n",
    "        actual = np.argmax(test)\r\n",
    "\r\n",
    "        matrix[actual][guess] += 1\r\n",
    "        \r\n",
    "    df_cm = pd.DataFrame(matrix, range(len(matrix)), range(len(matrix)))\r\n",
    "    int_cols = df_cm.columns\r\n",
    "    df_cm.columns = classes\r\n",
    "    df_cm.index = classes\r\n",
    "\r\n",
    "    fig = plt.figure(figsize=(10,7))\r\n",
    "    sn.set(font_scale=1.5) # for label size\r\n",
    "    ax = sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='g', cmap=sn.color_palette(\"Blues\")) # font size\r\n",
    "    ax.set_ylabel('Actual')\r\n",
    "    ax.set_xlabel('Predicted')\r\n",
    "    plt.tight_layout()\r\n",
    "    \r\n",
    "    fig.savefig('conf_matrix_{}.png'.format(file))\r\n",
    "\r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "def show_roc_curve(model=None, X_test=None, y_test=None, classes=[], file=''):\r\n",
    "    y_score = model.predict(X_test)\r\n",
    "    \r\n",
    "    n_classes = len(classes)\r\n",
    "    \r\n",
    "    # Produce ROC curve from https://hackernoon.com/simple-guide-on-how-to-generate-roc-plot-for-keras-classifier-2ecc6c73115a\r\n",
    "    # Note that I am working through this code and I'm going to clean it up as I learn more about how it works\r\n",
    "    import numpy as np\r\n",
    "    from numpy import interp\r\n",
    "    import matplotlib.pyplot as plt\r\n",
    "    from itertools import cycle\r\n",
    "    from sklearn.metrics import roc_curve, auc\r\n",
    "\r\n",
    "    # Plot linewidth.\r\n",
    "    lw = 2\r\n",
    "\r\n",
    "    # Compute ROC curve and ROC area for each class\r\n",
    "    fpr = dict()\r\n",
    "    tpr = dict()\r\n",
    "    roc_auc = dict()\r\n",
    "    for i in range(n_classes):\r\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\r\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\r\n",
    "\r\n",
    "    # Compute micro-average ROC curve and ROC area\r\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\r\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\r\n",
    "\r\n",
    "    # Compute macro-average ROC curve and ROC area\r\n",
    "\r\n",
    "    # First aggregate all false positive rates\r\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\r\n",
    "\r\n",
    "    # Then interpolate all ROC curves at this points\r\n",
    "    mean_tpr = np.zeros_like(all_fpr)\r\n",
    "    for i in range(n_classes):\r\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\r\n",
    "\r\n",
    "    # Finally average it and compute AUC\r\n",
    "    mean_tpr /= n_classes\r\n",
    "\r\n",
    "    fpr[\"macro\"] = all_fpr\r\n",
    "    tpr[\"macro\"] = mean_tpr\r\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\r\n",
    "\r\n",
    "    # Plot all ROC curves of all the classes\r\n",
    "    fig = plt.figure(figsize=(12,12))\r\n",
    "\r\n",
    "    colors = cycle(['red', 'blue', 'orange', 'green', 'violet', 'teal', 'turquoise', 'pink'])\r\n",
    "    for i, color in zip(range(n_classes), colors):\r\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\r\n",
    "                 label='ROC curve of {0} (area = {1:0.2f})'.format(classes[i], roc_auc[i]))\r\n",
    "\r\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\r\n",
    "    plt.xlim([0.0, 1.0])\r\n",
    "    plt.ylim([0.0, 1.05])\r\n",
    "    plt.ylabel('True Positive Rate (Sensativity)')\r\n",
    "    plt.xlabel('False Positive Rate (1-Specificity)')\r\n",
    "    plt.title('Receiver Operating Characteristic of the Classes')\r\n",
    "    plt.legend(loc=\"lower right\")\r\n",
    "    \r\n",
    "    fig.savefig('roc_curve_classes_{}.png'.format(file))\r\n",
    "    \r\n",
    "    plt.show()\r\n",
    "    \r\n",
    "     # Plot all ROC curves with micro and macro averages\r\n",
    "    fig = plt.figure(figsize=(12,12))\r\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\r\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\r\n",
    "                   ''.format(roc_auc[\"micro\"]),\r\n",
    "             color='deeppink', linestyle=':', linewidth=4)\r\n",
    "\r\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\r\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\r\n",
    "                   ''.format(roc_auc[\"macro\"]),\r\n",
    "             color='navy', linestyle=':', linewidth=4)\r\n",
    "\r\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\r\n",
    "    plt.xlim([0.0, 1.0])\r\n",
    "    plt.ylim([0.0, 1.05])\r\n",
    "    plt.ylabel('True Positive Rate (Sensativity)')\r\n",
    "    plt.xlabel('False Positive Rate (1-Specificity)')\r\n",
    "    plt.title('Receiver Operating Characteristic of the Micro and Macro Averages')\r\n",
    "    plt.legend(loc=\"lower right\")\r\n",
    "    \r\n",
    "    fig.savefig('roc_curve_micromacro_{}.png'.format(file))\r\n",
    "    \r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def get_std(x=[], xbar=0):\r\n",
    "    o2=0\r\n",
    "    for xi in x:\r\n",
    "        o2 += (xi - xbar)**2\r\n",
    "    o2 /= len(x)-1\r\n",
    "    return sqrt(o2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "baseline_df : pd.DataFrame = load_data(file_path_1)\r\n",
    "timebased_df: pd.DataFrame = load_data(file_path_2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Dataset: ../data/prepared/baseline/Benign_vs_DDoS.csv\n",
      "\tTo Dataset Cache: ../data/cache/baseline/Benign_vs_DDoS.csv.pickle\n",
      "\n",
      "Loading Dataset: ../data/prepared/timebased/Benign_vs_DDoS.csv\n",
      "\tTo Dataset Cache: ../data/cache/timebased/Benign_vs_DDoS.csv.pickle\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "dep_var = 'Label'\r\n",
    "\r\n",
    "ind_vars_baseline = (baseline_df.columns.difference([dep_var])).tolist()\r\n",
    "ind_vars_timebased = (timebased_df.columns.difference([dep_var])).tolist()\r\n",
    "\r\n",
    "baseline_Xy = (baseline_df[ind_vars_baseline], baseline_df[dep_var])\r\n",
    "timebased_Xy = (timebased_df[ind_vars_timebased], timebased_df[dep_var])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "names: list = ['Benign', 'DDoS']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "X = baseline_Xy[0]\r\n",
    "x = baseline_Xy[0]\r\n",
    "Y = baseline_Xy[1]\r\n",
    "\r\n",
    "num_classes = Y.nunique()\r\n",
    "\r\n",
    "encoder = LabelEncoder()\r\n",
    "y = encoder.fit_transform(Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Lists for accuracies collected from models\r\n",
    "list_rf = []\r\n",
    "list_dt = []\r\n",
    "list_knn = []\r\n",
    "list_dnn = []\r\n",
    "\r\n",
    "std_rf = []\r\n",
    "std_dt = [] \r\n",
    "std_knn = []\r\n",
    "std_dnn = []\r\n",
    "\r\n",
    "\r\n",
    "# Mean accuracies for each model\r\n",
    "mean_rf = 0\r\n",
    "mean_dt = 0\r\n",
    "mean_knn = 0\r\n",
    "mean_dnn = 0\r\n",
    "\r\n",
    "# Keep to calculate std\r\n",
    "results_rf = []\r\n",
    "results_dt = []\r\n",
    "results_knn = []  \r\n",
    "results_dnn = []\r\n",
    "\r\n",
    "# 10-fold Stratified Cross-Validation\r\n",
    "n_splits = 10\r\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\r\n",
    "for train_idxs, test_idxs in skf.split(X, y):\r\n",
    "    # Define the training and testing sets\r\n",
    "    X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\r\n",
    "    y_train, y_test = y[train_idxs], y[test_idxs]\r\n",
    "    \r\n",
    "    # Create a different version of the y_train and y_test for the Deep Neural Network\r\n",
    "    # y_train_dnn = to_categorical(y_train, num_classes=num_classes)\r\n",
    "    # y_test_dnn = to_categorical(y_test, num_classes=num_classes)\r\n",
    "    \r\n",
    "    # Initialize the sklearn models\r\n",
    "    rf = RandomForestClassifier(random_state=seed)\r\n",
    "    dt = DecisionTreeClassifier(random_state=seed)\r\n",
    "    knn = KNeighborsClassifier()\r\n",
    "    \r\n",
    "    # # Deep Neural Network\r\n",
    "    # dnn = Sequential([\r\n",
    "    #     Dense(256, input_shape=(69,)),\r\n",
    "    #     Dense(128, activation='relu'),\r\n",
    "    #     Dense(64, activation='relu'),\r\n",
    "    #     Dense(32, activation='relu'),\r\n",
    "    #     Dense(2, activation='softmax')\r\n",
    "    # ])\r\n",
    "    # dnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
    "    \r\n",
    "    \r\n",
    "    # Train the models\r\n",
    "    rf.fit(X_train, y_train)\r\n",
    "    dt.fit(X_train, y_train)\r\n",
    "    knn.fit(X_train, y_train)\r\n",
    "    # dnn.fit(x=X_train, y=y_train_dnn, batch_size=25, epochs=100, verbose=0, validation_data=(X_test, y_test_dnn))\r\n",
    "    \r\n",
    "    # Evaluate the models\r\n",
    "    results_rf.append(rf.score(X_test, y_test))\r\n",
    "    results_dt.append(dt.score(X_test, y_test))\r\n",
    "    results_knn.append(knn.score(X_test, y_test))  \r\n",
    "    # results_dnn.append( (dnn.evaluate(X_test, y_test_dnn, verbose=0) )[1] )\r\n",
    "    \r\n",
    "    # print('Random Forest')\r\n",
    "    # show_roc_curve(model=rf, X_test=X_test, y_test=y_test, classes=names)\r\n",
    "    # print('Decision Tree')\r\n",
    "    # show_roc_curve(model=dt, X_test=X_test, y_test=y_test, classes=names)\r\n",
    "    # print('k-Nearest Neighbor')\r\n",
    "    # show_roc_curve(model=knn, X_test=X_test, y_test=y_test, classes=names)\r\n",
    "    # # print('Deep Learning')\r\n",
    "    # show_roc_curve(model=dnn, X_test=X_test, y_test=y_test_dnn, classes=names)\r\n",
    "\r\n",
    "    print('Random Forest')\r\n",
    "    show_conf_matrix(model=rf, X_test=X_test, y_test=y_test, classes=names)\r\n",
    "    print('Decision Tree')\r\n",
    "    show_conf_matrix(model=dt, X_test=X_test, y_test=y_test, classes=names)\r\n",
    "    print('k-Nearest Neighbor')\r\n",
    "    show_conf_matrix(model=knn, X_test=X_test, y_test=y_test, classes=names)\r\n",
    "    # print('Deep Learning')\r\n",
    "    # show_conf_matrix(model=dnn, X_test=X_test, y_test=y_test_dnn, classes=names)        \r\n",
    "    \r\n",
    "    #print('Results from DNN: {}'.format(results_dnn))\r\n",
    "    \r\n",
    "    # Add the results to the running mean\r\n",
    "    mean_rf += results_rf[-1] / (n_splits * 1.0)\r\n",
    "    mean_dt += results_dt[-1] / (n_splits * 1.0)\r\n",
    "    mean_knn += results_knn[-1] / (n_splits * 1.0)\r\n",
    "    # mean_dnn += results_dnn[-1] / (n_splits * 1.0)\r\n",
    "    \r\n",
    "# Push the mean results from all of the splits to the lists\r\n",
    "list_rf.append(mean_rf)\r\n",
    "list_dt.append(mean_dt)\r\n",
    "list_knn.append(mean_knn)\r\n",
    "# list_dnn.append(mean_dnn)\r\n",
    "\r\n",
    "std_rf.append(get_std(results_rf, mean_rf))\r\n",
    "std_dt.append(get_std(results_dt, mean_dt))\r\n",
    "std_knn.append(get_std(results_knn, mean_knn))\r\n",
    "# std_dnn.append(get_std(results_dnn, mean_dnn))\r\n",
    "\r\n",
    "print('done')\r\n",
    "\r\n",
    "print('All trainings complete!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int32' has no len()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-09c7b7422b92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Random Forest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mshow_conf_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Decision Tree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mshow_conf_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-e6f197b1b71b>\u001b[0m in \u001b[0;36mshow_conf_matrix\u001b[1;34m(model, X_test, y_test, classes, file)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m  \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.int32' has no len()"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}