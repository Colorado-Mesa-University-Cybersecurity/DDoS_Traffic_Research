{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os, platform, pprint, sys\r\n",
    "import fastai\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import sklearn\r\n",
    "import yellowbrick as yb\r\n",
    "\r\n",
    "from fastai.tabular.data import TabularDataLoaders, TabularPandas\r\n",
    "from fastai.tabular.all import FillMissing, Categorify, Normalize, tabular_learner, accuracy, ClassificationInterpretation, ShowGraphCallback, RandomSplitter, range_of\r\n",
    "\r\n",
    "from sklearn.base import BaseEstimator\r\n",
    "from sklearn.metrics import accuracy_score, classification_report\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "\r\n",
    "from yellowbrick.model_selection import CVScores, LearningCurve, ValidationCurve\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "seed: int = 14\r\n",
    "\r\n",
    "\r\n",
    "# set up pretty printer for easier data evaluation\r\n",
    "pretty = pprint.PrettyPrinter(indent=4, width=30).pprint\r\n",
    "\r\n",
    "\r\n",
    "# declare file paths for the data we will be working on\r\n",
    "data_path_1: str = '../data/prepared/baseline/'\r\n",
    "data_path_2: str = '../data/prepared/timebased/'\r\n",
    "modelPath  : str = './models'\r\n",
    "\r\n",
    "\r\n",
    "# list the names of the datasets we will be using\r\n",
    "attacks : list = [ 'DNS', 'LDAP', 'MSSQL', 'NetBIOS', 'NTP', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDP', 'UDPLag' ]\r\n",
    "datasets: list = [\r\n",
    "    \"DNS_vs_benign.csv\" , \"LDAP_vs_benign.csv\"    , \"MSSQL_vs_benign.csv\" , \"NetBIOS_vs_benign.csv\" ,\r\n",
    "    \"NTP_vs_benign.csv\" , \"Portmap_vs_benign.csv\" , \"SNMP_vs_benign.csv\"  , \"SSDP_vs_benign.csv\"    ,\r\n",
    "    \"Syn_vs_benign.csv\" , \"TFTP_vs_benign.csv\"    , \"UDP_vs_benign.csv\"   , \"UDPLag_vs_benign.csv\"  ,\r\n",
    "]\r\n",
    "\r\n",
    "\r\n",
    "# set up enumeration of experiment types\r\n",
    "Baseline : int = 0\r\n",
    "Timebased: int = 1\r\n",
    "\r\n",
    "\r\n",
    "# print library and python versions for reproducibility\r\n",
    "print(\r\n",
    "    f'''\r\n",
    "    python:\\t{platform.python_version()}\r\n",
    "\r\n",
    "    \\tfastai:\\t\\t{fastai.__version__}\r\n",
    "    \\tmatplotlib:\\t{mpl.__version__}\r\n",
    "    \\tnumpy:\\t\\t{np.__version__}\r\n",
    "    \\tpandas:\\t\\t{pd.__version__}\r\n",
    "    \\tsklearn:\\t{sklearn.__version__}\r\n",
    "    \\tyellowbrick:\\t{yb.__version__}\r\n",
    "    '''\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_file_path(directory: str):\r\n",
    "    '''\r\n",
    "        Closure that will return a function that returns the filepath to the directory given to the closure\r\n",
    "    '''\r\n",
    "\r\n",
    "    def func(file: str) -> str:\r\n",
    "        return os.path.join(directory, file)\r\n",
    "\r\n",
    "    return func\r\n",
    "\r\n",
    "\r\n",
    "# use the get_file_path closure to create a function that will return the path to a file\r\n",
    "baseline_path  = get_file_path(data_path_1)\r\n",
    "timebased_path = get_file_path(data_path_2)\r\n",
    "\r\n",
    "\r\n",
    "# create a list of the paths to all of the dataset files\r\n",
    "baseline_files : list = list(map(baseline_path , datasets))\r\n",
    "timebased_files: list = list(map(timebased_path, datasets))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_data(filePath: str) -> pd.DataFrame:\r\n",
    "    '''\r\n",
    "        Loads the Dataset from the given filepath and caches it for quick access in the future\r\n",
    "        Function will only work when filepath is a .csv file\r\n",
    "    '''\r\n",
    "\r\n",
    "    # slice off the ./CSV/ from the filePath\r\n",
    "    if filePath[0] == '.' and filePath[1] == '.':\r\n",
    "        filePathClean: str = filePath[17::]\r\n",
    "        pickleDump: str = f'../data/cache/{filePathClean}.pickle'\r\n",
    "    else:\r\n",
    "        pickleDump: str = f'../data/cache/{filePath}.pickle'\r\n",
    "    \r\n",
    "    print(f'Loading Dataset: {filePath}')\r\n",
    "    print(f'\\tTo Dataset Cache: {pickleDump}\\n')\r\n",
    "    \r\n",
    "    # check if data already exists within cache\r\n",
    "    if os.path.exists(pickleDump):\r\n",
    "        df = pd.read_pickle(pickleDump)\r\n",
    "        \r\n",
    "    # if not, load data and cache it\r\n",
    "    else:\r\n",
    "        df = pd.read_csv(filePath, low_memory=True)\r\n",
    "        df.to_pickle(pickleDump)\r\n",
    "\r\n",
    "    \r\n",
    "    return df\r\n",
    "\r\n",
    "\r\n",
    "def run_experiment(df, name, binary=True):\r\n",
    "    '''\r\n",
    "        Run binary classification using K-Nearest Neighbors, saving the model as {name}.model\r\n",
    "    '''\r\n",
    "    dep_var: str = 'Label'\r\n",
    "    unused_categories: list = []\r\n",
    "    selected_features = list(set(df) - set(unused_categories) - set([dep_var]))\r\n",
    "\r\n",
    "    procs = [FillMissing, Categorify, Normalize]\r\n",
    "    splits = RandomSplitter(valid_pct=0.2, seed=seed)(range_of(df))\r\n",
    "    \r\n",
    "\r\n",
    "    to = TabularPandas(df, y_names=dep_var, cat_names=[], cont_names=selected_features, procs=procs, splits=splits)\r\n",
    "\r\n",
    "    dls = to.dataloaders(bs=64)\r\n",
    "    mds = tabular_learner(dls)\r\n",
    "\r\n",
    "    X_train = to.train.xs.reset_index(drop=True)\r\n",
    "    X_test = to.valid.xs.reset_index(drop=True)\r\n",
    "    y_train = to.train.ys.values.ravel()\r\n",
    "    y_test = to.valid.ys.values.ravel()\r\n",
    "\r\n",
    "    # model = KNeighborsClassifier()\r\n",
    "    model = SVC(random_state=seed)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    prediction = model.predict(X_test)\r\n",
    "    report = classification_report(y_test, prediction)\r\n",
    "    print(report)\r\n",
    "\r\n",
    "    if binary:\r\n",
    "        model.target_type_ = 'binary'\r\n",
    "    else:  \r\n",
    "        model.target_type_ = 'multiclass'\r\n",
    "\r\n",
    "\r\n",
    "    classes : list = list(mds.dls.vocab)\r\n",
    "    viz_data: tuple = (model, classes, X_test, y_test, name, X_train, y_train)\r\n",
    "\r\n",
    "    visualizer = LearningCurve(model, scoring='f1_weighted')\r\n",
    "    visualizer.fit(X_test, y_test)\r\n",
    "    visualizer.show()\r\n",
    "\r\n",
    "    return viz_data\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def visualize_confusion_matrix(viz_data):\r\n",
    "\r\n",
    "    visualizer = yb.classifier.ConfusionMatrix(viz_data[0], classes=viz_data[1], title=viz_data[4])\r\n",
    "    visualizer.score(viz_data[2], viz_data[3])\r\n",
    "    visualizer.show()\r\n",
    "\r\n",
    "def visualize_roc(viz_data):\r\n",
    "\r\n",
    "    visualizer = yb.classifier.ROCAUC(viz_data[0], classes=viz_data[1], title=viz_data[4])\r\n",
    "    visualizer.score(viz_data[2], viz_data[3])\r\n",
    "    visualizer.poof()\r\n",
    "\r\n",
    "def visualize_pr_curve(viz_data):\r\n",
    "\r\n",
    "    visualizer = yb.classifier.PrecisionRecallCurve(viz_data[0], title=viz_data[4])\r\n",
    "    visualizer.score(viz_data[2], viz_data[3])\r\n",
    "    visualizer.poof()\r\n",
    "\r\n",
    "def visualize_report(viz_data):\r\n",
    "\r\n",
    "    visualizer = yb.classifier.ClassificationReport(viz_data[0], classes=viz_data[1], title=viz_data[4], support=True)\r\n",
    "    visualizer.score(viz_data[2], viz_data[3])\r\n",
    "    visualizer.poof()\r\n",
    "\r\n",
    "def visualize_class_balance(viz_data):\r\n",
    "\r\n",
    "    visualizer = yb.target.ClassBalance(labels=viz_data[1])\r\n",
    "    visualizer.fit(viz_data[6], viz_data[3])\r\n",
    "    visualizer.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "baseline_dfs : map = map(load_data   , baseline_files )\r\n",
    "timebased_dfs: map = map(load_data   , timebased_files)\r\n",
    "experiments  : zip = zip(baseline_dfs, timebased_dfs  , attacks)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def experiment_runner():\r\n",
    "    num = 1\r\n",
    "    for baseline, timebased, info in experiments:\r\n",
    "        print(f'Running experiment #{num}:\\t{info}')\r\n",
    "\r\n",
    "        print('Baseline results')\r\n",
    "        baseline_results = run_experiment(baseline, f'{info}_vs_benign_KNN_baseline')\r\n",
    "        \r\n",
    "        print('\\nTime-based results')\r\n",
    "        timebased_results = run_experiment(timebased, f'{info}_vs_benign_KNN_timebased')\r\n",
    "        \r\n",
    "        num += 1\r\n",
    "        yield (baseline_results, timebased_results)\r\n",
    "\r\n",
    "\r\n",
    "experiment = experiment_runner()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = next(experiment)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "visualize_report(results[Baseline])\r\n",
    "visualize_report(results[Timebased])\r\n",
    "visualize_confusion_matrix(results[Baseline])\r\n",
    "visualize_confusion_matrix(results[Timebased])\r\n",
    "visualize_pr_curve(results[Baseline])\r\n",
    "visualize_pr_curve(results[Timebased])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}